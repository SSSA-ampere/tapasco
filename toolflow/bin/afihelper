#!/usr/bin/env python3

#
# Copyright (c) 2014-2020 Embedded Systems and Applications, TU Darmstadt.
#
# This file is part of TaPaSCo 
# (see https://github.com/esa-tu-darmstadt/tapasco).
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Lesser General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.
#

"""
Helper script for creating AFIs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This script allows the user to upload a given .tar-file to an Amazon S3
bucket and to create an AFI (Amazon FPGA Image) from that file.

The AWS environment must be configured, for example by using the AWS CLI
and running `aws configure`, where the required credentials can be entered.
For more information see: https://aws.amazon.com/de/cli/
"""

import boto3

import os
import sys
import uuid
import shutil
import logging
import argparse
import datetime
import threading
import subprocess

# https://boto3.amazonaws.com/v1/documentation/api/latest/_modules/boto3/s3/transfer.html


class ProgressPercentage(object):
    def __init__(self, filename):
        self._filename = filename
        self._size = float(os.path.getsize(filename))
        self._seen_so_far = 0
        self._lock = threading.Lock()

    def __call__(self, bytes_amount):
        # To simplify we'll assume this is hooked up
        # to a single filename.
        with self._lock:
            self._seen_so_far += bytes_amount
            percentage = (self._seen_so_far / self._size) * 100
            sys.stdout.write(
                "\r%s  %s / %s  (%.2f%%)" % (
                    self._filename, self._seen_so_far, self._size,
                    percentage))
            sys.stdout.flush()


default_region = boto3.session.Session().region_name

parser = argparse.ArgumentParser(description='Helper script for creating AFIs')
parser.add_argument(
    'bucket',
    help='name of the target S3 bucket (created when not existing)')
parser.add_argument('tarfile',
                    help='filename of the tar file to create an AFI from')
parser.add_argument('name', help='name of the AFI')
parser.add_argument('--dry-run', default=False, action='store_true',
                    help='dry run operation')
parser.add_argument('--no-wait', default=False, action='store_true',
                    help='do not wait for AFI generation to complete')
parser.add_argument('--verbose', default=False, action='store_true',
                    help='be more talkative')
parser.add_argument('--description', default=False,
                    help='description of the AFI')
parser.add_argument(
    '--region',
    default=default_region,
    help='region to use (currently configured: {})'.format(default_region))

args = parser.parse_args()

if args.verbose:
    boto3.set_stream_logger('boto3.resources', logging.DEBUG)

if not os.path.isfile(args.tarfile):
    print('ERROR: File does not exist')
    exit(1)

s3 = boto3.resource('s3')

try:
    if args.region == 'us-east-1':
        s3.create_bucket(Bucket=args.bucket)
    else:
        s3.create_bucket(
            Bucket=args.bucket,
            CreateBucketConfiguration={'LocationConstraint': args.region}
        )
except s3.meta.client.exceptions.BucketAlreadyOwnedByYou:
    pass

s3.Object(args.bucket, 'logs/').put()

fname = os.path.basename(args.tarfile)
transfer = boto3.s3.transfer.S3Transfer(s3.meta.client)
transfer.upload_file(args.tarfile, args.bucket, fname,
                     callback=ProgressPercentage(args.tarfile))
print('\nUpload finished')

ec2 = boto3.resource('ec2')

token = uuid.uuid4().hex
description = args.description or 'Created from {} at {}'.format(
    fname, datetime.datetime.now().isoformat())

response = ec2.meta.client.create_fpga_image(
    DryRun=args.dry_run,
    InputStorageLocation={
        'Bucket': args.bucket,
        'Key': fname
    },
    LogsStorageLocation={
        'Bucket': args.bucket,
        'Key': 'logs'
    },
    Description=description,
    Name=args.name,
    ClientToken=token
)

print('FpgaImageGlobalId = {}'.format(response['FpgaImageGlobalId']))
print('FpgaImageId       = {}'.format(response['FpgaImageId']))

if not args.no_wait:
    if shutil.which('wait_for_afi.py') is None:
        print(
            'Cannot wait for AFI generation because `wait_for_afi.py` ' +
            'is not in PATH.'
        )
    else:
        subprocess.call(['wait_for_afi.py', '--afi', response['FpgaImageId']])

# vim: set expandtab ts=4 sw=4:
